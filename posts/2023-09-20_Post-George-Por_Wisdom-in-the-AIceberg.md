---
title: "Wisdom in the AIceberg"
author: "George Pór"
issue_slug: "2023-09-20"
tags: ['Events and Gatherings', 'Narrative and Storytelling']
---

# Wisdom in the AIceberg

**Author:** [[George Pór]]
**Issue:** [2023-09-20](https://plex.collectivesensecommons.org/2023-09-20/)

---

## Wisdom in the AIceberg
by **George Pór**

*[Image not included in the current archive. Images may be included in the future.]*

In a recent conversation in a Discord channel, a colleague quoted a panel commentator saying,

how linguistic choices around AI such as “hallucination”, “emergence” and even “intelligence” are tactics tech companies use to try to humanise AI. Which allows them to position AI as a mystical object worth being curious about, therefore, increasing their use. In essence, (the commentator specifying that) AI being nothing but a “stochastic parrot” which is neither artificial nor intelligent.  My colleague added:

I am not surprised about hearing negative perspectives around AI’s development. The worry around who controls AI and how it’s projected is pragmatic. Shutting one down from exploring possibilities of a technology's potential capabilities isn’t - in my opinion... Being 100% content about one’s conclusions is in no other sector riskier than in futures thinking. He asked:

What are your thoughts on that?I replied:

that’s true, and the AIceberg model explained [here](https://technoshaman.medium.com/ai-and-wisdom-ce0cd11db218) may help us understand why it is so. Anyway, we can’t change people’s beliefs but we can move the edge of what is possible if we provide opportunities for new experiences by action design, action research, workshops, learning expeditions, rapid prototyping of Minimum Lovable Products, etc, no? 

____________________

Btw, I try to walk my talk about action research by being the instigator for one about the Rise of Compassionate AI. On 13-Sept-2023, we had its **Orientation to WHAT** workshop (on Zoom + Miro), which will be followed by the **Orientation to HOW** (methodology) and **Orientation to WHEN** (roadmapping) workshops. 

This research is conducted in partnership between RADAR and Future HOW. Our high-level research hypothesis is this:

A new social life form, the human-AI collective symbiont, can evolve from the Collaborative Hybrid Intelligence (CHI) of networked human and AI agents. **To the extent that the cultivation of CHI is guided by the deepest wisdom and highest consciousness available to the collaboration, CHI and the resulting symbiont can demonstrate qualities of wisdom and compassion, promoting the flourishing of All.**

Obviously, we need to develop pragmatic ways to validate that high-level hypothesis, by crafting relevant experiments with measurable indicators. That’s what we use our Generative Action Research for. The research is presently self-funded. Grant writing support (with %-based reward) is welcome.

---

**Related:**
- [[George Pór]] (author)
- [[2023]] (year)
- Topics: [[Events and Gatherings]], [[Narrative and Storytelling]]

